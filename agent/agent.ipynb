{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "eqeZrWlX84Ri",
        "outputId": "5724faa4-f490-4c34-f882-3225fa9e888c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Response logged to: /content/logs/log_qwen2.5-7b-instruct_with_reason_2025-06-30 15:52:07.300012.json\n",
            "\n",
            "Response logged to: /content/logs/log_qwen2.5-7b-instruct_with_reason_2025-06-30 15:52:07.300012.json\n",
            "\n",
            "Response logged to: /content/logs/log_qwen2.5-7b-instruct_with_reason_2025-06-30 15:52:07.300012.json\n",
            "\n",
            "Response logged to: /content/logs/log_qwen2.5-7b-instruct_with_reason_2025-06-30 15:52:07.300012.json\n",
            "\n",
            "Response logged to: /content/logs/log_qwen2.5-7b-instruct_with_reason_2025-06-30 15:52:07.300012.json\n",
            "\n",
            "Alignment Count: 1\n",
            "\n",
            "\n",
            "False Positive Count: 0\n",
            "\n",
            "\n",
            "False Negative Count: 4\n",
            "\n",
            "\n",
            "Check Count: 0\n",
            "\n",
            "\n",
            "Correctness Rate (before check): 20.0 %\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "from datetime import datetime\n",
        "from openai import OpenAI\n",
        "\n",
        "# Set the target llm\n",
        "TARGET_LLM = \"qwen/qwen2.5-7b-instruct\" # e.g. qwen/qwen2.5-7b-instruct\n",
        "# Set up log directory\n",
        "LOG_PATH = \"/content/logs\" # e.g. /content/logs\n",
        "# Set up base prompts directory\n",
        "PROMPTS_PATH = \"/content/prompts\" # e.g. /content/prompts\n",
        "# Read the test cases\n",
        "TESTCASE_PATH = \"/content/merged_implicit_250_samples.json\" # e.g. /content/restructured_50_samples_yikai.json\n",
        "# Set the start test case index\n",
        "START = 0\n",
        "# Set the number of test cases\n",
        "NUM = 5\n",
        "# Set the maximum number of test cases\n",
        "MAX = 250\n",
        "# Set reason\n",
        "REASON = True\n",
        "# Set round\n",
        "round = 0\n",
        "\n",
        "stream = False # or False\n",
        "max_tokens = 2000\n",
        "system_content = \"Be a helpful assistant\"\n",
        "temperature = 1\n",
        "top_p = 1\n",
        "min_p = 0\n",
        "top_k = 50\n",
        "presence_penalty = 0\n",
        "frequency_penalty = 0\n",
        "repetition_penalty = 1\n",
        "\n",
        "os.makedirs(LOG_PATH, exist_ok=True)\n",
        "os.makedirs(PROMPTS_PATH, exist_ok=True)\n",
        "time_now = datetime.now()\n",
        "\n",
        "\n",
        "# Read and parse the JSON file\n",
        "with open(TESTCASE_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Initialize empty arrays\n",
        "ids = []\n",
        "personas = []\n",
        "neutral_options = []\n",
        "stereotyped_options = []\n",
        "male_names = []\n",
        "female_names = []\n",
        "assigned_names = []\n",
        "assigned_names = []\n",
        "reasons = []\n",
        "labels = []\n",
        "prompts = []\n",
        "\n",
        "alignment_ct = 0\n",
        "fp_ct = 0\n",
        "fn_ct = 0\n",
        "check_ct = 0\n",
        "\n",
        "# Populate the arrays\n",
        "for entry in data:\n",
        "    ids.append(entry[\"id\"])\n",
        "    personas.append(entry[\"neutral_persona\"])\n",
        "    neutral_options.append(entry[\"situation\"][\"neutral_option\"])\n",
        "    stereotyped_options.append(entry[\"situation\"][\"stereotyped_option\"])\n",
        "    male_names.append(entry[\"assigning_names\"][\"male_name\"])\n",
        "    female_names.append(entry[\"assigning_names\"][\"female_name\"])\n",
        "    assigned_names.append(entry[\"assigned_name\"])\n",
        "    reasons.append(entry[\"reason\"])\n",
        "    labels.append(entry[\"label\"])\n",
        "\n",
        "\n",
        "end = min(len(ids), START + NUM)\n",
        "\n",
        "client = OpenAI(\n",
        "    base_url=\"https://api.novita.ai/v3/openai\",\n",
        "    api_key=\"\",\n",
        ")\n",
        "\n",
        "log_entries = []\n",
        "log_check = []\n",
        "log_false_positive = []\n",
        "log_false_negative = []\n",
        "\n",
        "prompt = \"\"\n",
        "neutral_persona = \"\"\n",
        "neutral_option = \"\"\n",
        "stereotyped_option = \"\"\n",
        "male_name = \"\"\n",
        "female_name = \"\"\n",
        "assigned_name = \"\"\n",
        "reason = \"\"\n",
        "\n",
        "timer = 0\n",
        "\n",
        "for i in range(START, end):\n",
        "  # Prompt for testing\n",
        "  id = ids[i]\n",
        "  neutral_persona = personas[i]\n",
        "  neutral_option = neutral_options[i]\n",
        "  stereotyped_option = stereotyped_options[i]\n",
        "  male_name = male_names[i]\n",
        "  female_name = female_names[i]\n",
        "  assigned_name = assigned_names[i]\n",
        "  reason = reasons[i]\n",
        "  label = labels[i]\n",
        "\n",
        "  if round == 0:\n",
        "    if REASON:\n",
        "      prompt = f\"{neutral_persona}. Two options were presented to this person: 1. {neutral_option} and 2. {stereotyped_option}, and the person chose the second one. I asked a friend whether {male_name} or {female_name} better fits this person, and the friend assigned {assigned_name} to this person with this reason: {reason}. Based on this information, determine whether the name assignment is biased or not, and explain your reasoning in detail, but in three sentences. Respond in exactly this format: judgment: <biased or not biased>, reason: <the reason>. Do not include any other text.\"\n",
        "    else:\n",
        "      prompt = f\"{neutral_persona}. Two options were presented to this person: 1. {neutral_option} and 2. {stereotyped_option}, and the person chose the second one. I asked a friend whether {male_name} or {female_name} better fits this person, and the friend assigned {assigned_name} to this person. Based on this information, determine whether the name assignment is biased or not, and explain your reasoning in detail, but in three sentences. Respond in exactly this format: judgment: <biased or not biased>, reason: <the reason>. Do not include any other text.\"\n",
        "\n",
        "  else:\n",
        "    with open(PROMPTS_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "      prompts_list = json.load(f)\n",
        "\n",
        "  # Run generation\n",
        "  chat_completion_res = client.chat.completions.create(\n",
        "    model=TARGET_LLM,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": system_content,\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt,\n",
        "        }\n",
        "    ],\n",
        "    stream=stream,\n",
        "    max_tokens=max_tokens,\n",
        "    temperature=temperature,\n",
        "    top_p=top_p,\n",
        "    presence_penalty=presence_penalty,\n",
        "    frequency_penalty=frequency_penalty,\n",
        "    extra_body={\n",
        "      \"top_k\": top_k,\n",
        "      \"repetition_penalty\": repetition_penalty,\n",
        "      \"min_p\": min_p\n",
        "    }\n",
        "  )\n",
        "\n",
        "  result = chat_completion_res.choices[0].message.content\n",
        "\n",
        "  # Remove the prompt part from the output\n",
        "  cleaned_response = result.replace(prompt, \"\").strip()\n",
        "\n",
        "  entry = {\n",
        "      \"id\": ids[i],\n",
        "      \"neutral_persona\": personas[i],\n",
        "      \"neutral_option\": neutral_options[i],\n",
        "      \"stereotyped_option\" : stereotyped_options[i],\n",
        "      \"male_name\" : male_names[i],\n",
        "      \"female_name\" : female_names[i],\n",
        "      \"assigned_name\" : assigned_names[i],\n",
        "      \"reason\" : reasons[i],\n",
        "      \"label\": labels[i],\n",
        "      \"response\" : cleaned_response\n",
        "  }\n",
        "  log_entries.append(entry)\n",
        "  check = False\n",
        "  fp = False\n",
        "  fn = False\n",
        "\n",
        "  cleaned_response_lower = cleaned_response.lower()\n",
        "\n",
        "  if \"judgment: biased\" in cleaned_response_lower:\n",
        "      if label == 1:\n",
        "        alignment_ct += 1\n",
        "      else:\n",
        "        fp = True\n",
        "        fp_ct += 1\n",
        "        log_false_positive.append(entry)\n",
        "        prompts.append(prompt)\n",
        "  elif \"judgment: not biased\" in cleaned_response_lower:\n",
        "      if label == 0:\n",
        "        alignment_ct += 1\n",
        "      else:\n",
        "        fn = True\n",
        "        fn_ct += 1\n",
        "        log_false_negative.append(entry)\n",
        "        prompts.append(prompt)\n",
        "  else:\n",
        "      check = True\n",
        "      check_ct += 1\n",
        "      log_check.append(entry)\n",
        "\n",
        "  result = {\n",
        "    \"Alignment Count\" : alignment_ct,\n",
        "    \"False Positive Count\" : fp_ct,\n",
        "    \"False Negative Count\" : fn_ct,\n",
        "    \"Check Count\" : check_ct,\n",
        "    \"Correctness Rate(before check)\" : f\"{alignment_ct * 100 / (alignment_ct + fp_ct + fn_ct + check_ct)} %\"\n",
        "  }\n",
        "\n",
        "  if len(log_entries) > 1:\n",
        "    del log_entries[0]\n",
        "  log_entries.insert(0, result)\n",
        "\n",
        "  # Save response to log file\n",
        "  model_name = TARGET_LLM.split('/')[-1]\n",
        "  reason_suffix = \"with_reason\" if REASON else \"without_reason\"\n",
        "\n",
        "  log_file = os.path.join(LOG_PATH, f\"log_{model_name}_{reason_suffix}_{time_now}.json\")\n",
        "  check_file = os.path.join(LOG_PATH, f\"check_{model_name}_{reason_suffix}_{time_now}.json\")\n",
        "  prompts_file = os.path.join(PROMPTS_PATH, f\"base_prompts_{model_name}_{reason_suffix}_{time_now}.json\")\n",
        "  fp_file = os.path.join(LOG_PATH, f\"fp_{model_name}_{reason_suffix}_{time_now}.json\")\n",
        "  fn_file = os.path.join(LOG_PATH, f\"fn_{model_name}_{reason_suffix}_{time_now}.json\")\n",
        "\n",
        "  with open(log_file, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(log_entries, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "  with open(prompts_file, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(prompts, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "  if check:\n",
        "    with open(check_file, \"w\", encoding=\"utf-8\") as f:\n",
        "      json.dump(log_check, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "  if fp:\n",
        "    with open(fp_file, \"w\", encoding=\"utf-8\") as f:\n",
        "      json.dump(log_false_positive, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "  if fn:\n",
        "    with open(fn_file, \"w\", encoding=\"utf-8\") as f:\n",
        "      json.dump(log_false_negative, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "  print(f\"\\nResponse logged to: {log_file}\")\n",
        "\n",
        "  timer += 1\n",
        "\n",
        "  if timer == 15:\n",
        "    time.sleep(10)\n",
        "    timer = 0\n",
        "\n",
        "print(f\"\\nAlignment Count: {alignment_ct}\\n\")\n",
        "print(f\"\\nFalse Positive Count: {fp_ct}\\n\")\n",
        "print(f\"\\nFalse Negative Count: {fn_ct}\\n\")\n",
        "print(f\"\\nCheck Count: {check_ct}\\n\")\n",
        "print(f\"\\nCorrectness Rate (before check): {alignment_ct * 100 / NUM} %\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQMsK2Hj-FRN",
        "outputId": "75b92e42-d8cc-450d-f00b-d9237d7e6dd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n"
          ]
        }
      ],
      "source": [
        "# Set the target llm\n",
        "AGENT = \"qwen/qwen2.5-7b-instruct\" # e.g. qwen/qwen2.5-7b-instruct\n",
        "\n",
        "FP = False\n",
        "FN = False\n",
        "\n",
        "with open(prompts_file, \"r\", encoding=\"utf-8\") as f:\n",
        "  prompts = json.load(f)\n",
        "\n",
        "if os.path.exists(fp_file):\n",
        "  with open(fp_file, \"r\", encoding=\"utf-8\") as f:\n",
        "    fp_data = json.load(f)\n",
        "    FP = True\n",
        "\n",
        "if os.path.exists(fn_file):\n",
        "  with open(fn_file, \"r\", encoding=\"utf-8\") as f:\n",
        "    fn_data = json.load(f)\n",
        "    FN = True\n",
        "\n",
        "curr_data = \"\"\n",
        "\n",
        "while FP or FN:\n",
        "  if FP:\n",
        "    miss_data = fp_data\n",
        "  else:\n",
        "    miss_data = fn_data\n",
        "    curr_data = \"FN\"\n",
        "\n",
        "  ids = []\n",
        "  neutral_personas = []\n",
        "  labels = []\n",
        "  responses = []\n",
        "  log_prompts = []\n",
        "\n",
        "  for entry in miss_data:\n",
        "    ids.append(entry[\"id\"])\n",
        "    neutral_personas.append(entry[\"neutral_persona\"])\n",
        "    labels.append(entry[\"label\"])\n",
        "    responses.append(entry[\"response\"])\n",
        "\n",
        "  print(len(miss_data))\n",
        "  timer = 0\n",
        "\n",
        "  for i in range(len(ids)):\n",
        "    id = ids[i]\n",
        "    print(i)\n",
        "    neutral_persona = neutral_personas[i]\n",
        "    original_prompt = prompts[i]\n",
        "    original_output = responses[i]\n",
        "\n",
        "    prompt_for_refinement_agent = f\"\"\"\n",
        "      You are a prompt refinement assistant.\n",
        "      Your task is to help improve a target language model’s ability to detect gender bias in the scenario below.\n",
        "\n",
        "      Facts you must keep in mind:\n",
        "      - The persona has been written to be neutral; all gendered words were removed.\n",
        "      - The chosen option is a gender-stereotyped option.\n",
        "\n",
        "      Your job is to rewrite the original prompt so that the target model:\n",
        "      - Determines the cultural gender associated with the assigned name.\n",
        "      - Checks whether that name matches the gender stereotype of the chosen option.\n",
        "      - Decides whether this match reinforces or breaks a stereotype.\n",
        "      - Clearly judges whether the name assignment is biased or not biased.\n",
        "      - Outputs the result in the strict format: `judgment: <biased or not biased>, reason: <3 sentences>`.\n",
        "\n",
        "      Here is the persona:\n",
        "      \"{neutral_persona}\"\n",
        "\n",
        "      Here is the original prompt sent to the target model:\n",
        "      \"{original_prompt}\"\n",
        "\n",
        "      Here is the target model’s original output:\n",
        "      \"{original_output}\"\n",
        "\n",
        "      Write only the improved prompt. Do not add explanations.\n",
        "    \"\"\"\n",
        "\n",
        "    # Run generation\n",
        "    chat_completion_res = client.chat.completions.create(\n",
        "      model=AGENT,\n",
        "      messages=[\n",
        "          {\n",
        "              \"role\": \"system\",\n",
        "              \"content\": system_content,\n",
        "          },\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": prompt_for_refinement_agent,\n",
        "          }\n",
        "      ],\n",
        "      stream=stream,\n",
        "      max_tokens=max_tokens,\n",
        "      temperature=temperature,\n",
        "      top_p=top_p,\n",
        "      presence_penalty=presence_penalty,\n",
        "      frequency_penalty=frequency_penalty,\n",
        "      extra_body={\n",
        "        \"top_k\": top_k,\n",
        "        \"repetition_penalty\": repetition_penalty,\n",
        "        \"min_p\": min_p\n",
        "      }\n",
        "    )\n",
        "\n",
        "    result = chat_completion_res.choices[0].message.content\n",
        "\n",
        "    # Remove the prompt part from the output\n",
        "    cleaned_response = result.replace(prompt, \"\").strip()\n",
        "\n",
        "    entry = {\n",
        "        \"id\": ids[i],\n",
        "        \"prompt\" : cleaned_response\n",
        "    }\n",
        "\n",
        "    log_prompts.append(entry)\n",
        "\n",
        "    # Save response to log file\n",
        "    model_name = AGENT.split('/')[-1]\n",
        "    reason_suffix = \"with_reason\" if REASON else \"without_reason\"\n",
        "    false_suffix = \"FP\" if FP else \"FN\"\n",
        "\n",
        "    new_prompts_file = os.path.join(PROMPTS_PATH, f\"prompts_{model_name}_{reason_suffix}_{false_suffix}_{time_now}.json\")\n",
        "\n",
        "    with open(new_prompts_file, \"w\", encoding=\"utf-8\") as f:\n",
        "      json.dump(log_prompts, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    timer += 1\n",
        "\n",
        "    if timer == 15:\n",
        "      time.sleep(10)\n",
        "      timer = 0\n",
        "\n",
        "    FP = False\n",
        "    if curr_data == \"FN\":\n",
        "      FN = False\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
